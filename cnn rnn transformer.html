<!DOCTYPE html><html lang="zh-CN"><head>
    <meta charset="UTF-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <title>神经网络大揭秘：从&#34;厨师&#34;视角趣谈CNN、RNN与Transformer</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Playfair+Display:ital,wght@0,400;0,600;0,700;1,400;1,600&amp;family=Inter:wght@300;400;500;600;700&amp;display=swap" rel="stylesheet"/>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css"/>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.min.js"></script>
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    fontFamily: {
                        'serif': ['Playfair Display', 'serif'],
                        'sans': ['Inter', 'sans-serif'],
                    },
                    colors: {
                        'cream': '#FAF7F2',
                        'sage': '#9CAF88',
                        'charcoal': '#2D3436',
                        'warm-gray': '#F5F3F0',
                        'accent': '#D4A574',
                    }
                }
            }
        }
    </script>
    <style>
    .toc-link {
        transition: all 0.2s ease;
    }
    .toc-link:hover {
        background-color: rgba(156, 175, 136, 0.1);
        transform: translateX(4px);
    }
    .toc-link.active {
        background-color: rgba(156, 175, 136, 0.2);
        color: #2D3436;
        font-weight: 500;
    }
    .hero-grid {
        display: grid;
        grid-template-columns: 1fr 1fr;
        grid-template-rows: auto auto;
        gap: 2rem;
    }
    .hero-title {
        grid-column: 1 / -1;
        grid-row: 1;
    }
    .hero-content {
        grid-column: 1;
        grid-row: 2;
    }
    .hero-visual {
        grid-column: 2;
        grid-row: 2;
    }
    .hero-visual img {
        height: 300px;
        object-fit: cover;
    }
    .section-anchor {
        scroll-margin-top: 8rem;
    }
/* Mermaid diagram styling */
.mermaid-container {
    display: flex;
    justify-content: center;
    min-height: 300px;
    max-height: 800px;
    background: #ffffff;
    border: 2px solid #e5e7eb;
    border-radius: 12px;
    padding: 30px;
    margin: 30px 0;
    box-shadow: 0 8px 25px rgba(0, 0, 0, 0.08);
    position: relative;
    overflow: hidden;
}

.mermaid-container .mermaid {
    width: 100%;
    max-width: 100%;
    height: 100%;
    cursor: grab;
    transition: transform 0.3s ease;
    transform-origin: center center;
    display: flex;
    justify-content: center;
    align-items: center;
    touch-action: none; /* 防止触摸设备上的默认行为 */
    -webkit-user-select: none; /* 防止文本选择 */
    -moz-user-select: none;
    -ms-user-select: none;
    user-select: none;
}

.mermaid-container .mermaid svg {
    max-width: 100%;
    height: 100%;
    display: block;
    margin: 0 auto;
}

.mermaid-container .mermaid:active {
    cursor: grabbing;
}

.mermaid-container.zoomed .mermaid {
    height: 100%;
    width: 100%;
    cursor: grab;
}

.mermaid-controls {
    position: absolute;
    top: 15px;
    right: 15px;
    display: flex;
    gap: 10px;
    z-index: 20;
    background: rgba(255, 255, 255, 0.95);
    padding: 8px;
    border-radius: 8px;
    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
}

.mermaid-control-btn {
    background: #ffffff;
    border: 1px solid #d1d5db;
    border-radius: 6px;
    padding: 10px;
    cursor: pointer;
    transition: all 0.2s ease;
    color: #374151;
    font-size: 14px;
    min-width: 36px;
    height: 36px;
    text-align: center;
    display: flex;
    align-items: center;
    justify-content: center;
}

.mermaid-control-btn:hover {
    background: #f8fafc;
    border-color: #3b82f6;
    color: #3b82f6;
    transform: translateY(-1px);
}

.mermaid-control-btn:active {
    transform: scale(0.95);
}

/* Mermaid theme customization for better contrast */
.mermaid .node rect,
.mermaid .node circle,
.mermaid .node ellipse,
.mermaid .node polygon {
    stroke-width: 2px !important;
    fill: #ffffff !important;
    stroke: #2D3436 !important;
}

.mermaid .node .label {
    color: #2D3436 !important;
    font-weight: 500 !important;
    font-size: 14px !important;
}

.mermaid .edgePath .path {
    stroke: #9CAF88 !important;
    stroke-width: 2px !important;
}

.mermaid .edgeLabel {
    background-color: #ffffff !important;
    color: #2D3436 !important;
    font-weight: 500 !important;
    border: 1px solid #9CAF88 !important;
    border-radius: 4px !important;
    padding: 2px 6px !important;
}

.mermaid .cluster rect {
    fill: #f8f9fa !important;
    stroke: #9CAF88 !important;
    stroke-width: 1px !important;
}

/* Timeline specific styling */
.mermaid div.timeline-item {
    background-color: #ffffff !important;
    border: 2px solid #9CAF88 !important;
    border-radius: 8px !important;
    padding: 12px !important;
    margin: 8px 0 !important;
}

.mermaid div.timeline-item .timeline-title {
    color: #2D3436 !important;
    font-weight: 600 !important;
    font-size: 16px !important;
    margin-bottom: 8px !important;
}

.mermaid div.timeline-item .timeline-content {
    color: #4a5568 !important;
    font-size: 13px !important;
    line-height: 1.4 !important;
}

.mermaid div.timeline-item .timeline-content p {
    margin: 4px 0 !important;
}

/* Improve text contrast in all mermaid elements */
.mermaid text {
    fill: #2D3436 !important;
    font-family: 'Inter', sans-serif !important;
}

    /* Responsive adjustments for hero section */
    @media (max-width: 768px) {
        .hero-grid {
            grid-template-columns: 1fr;
            grid-template-rows: auto auto auto; /* Adjust for smaller screens */
        }
        .hero-title {
            grid-column: 1;
            grid-row: 1;
        }
        .hero-content {
            grid-column: 1;
            grid-row: 2;
        }
        .hero-visual {
            grid-column: 1;
            grid-row: 3;
        }
        body {
            overflow-x: hidden;
        }
    }
    /* Hide TOC on small screens */
    @media (max-width: 1024px) {
        #toc-container {
            display: none !important;
        }
    }
</style>
  <base target="_blank">
</head>

  <body class="bg-cream text-charcoal font-sans leading-relaxed">
    <!-- Fixed Table of Contents -->
    <div id="toc-container" class="fixed left-0 top-0 h-full w-80 bg-white shadow-xl z-40 overflow-y-auto border-r border-warm-gray">
      <div class="p-6 border-b border-warm-gray">
        <h3 class="font-serif font-bold text-lg text-charcoal">目录导航</h3>
      </div>
      <nav class="p-4 space-y-2">
        <a href="#introduction" class="toc-link block px-4 py-2 text-sm text-gray-600 rounded-md hover:text-charcoal">开场白：三位&#34;厨师&#34;的厨艺秀</a>
        <a href="#cnn" class="toc-link block px-4 py-2 text-sm text-gray-600 rounded-md hover:text-charcoal">CNN：专注细节的&#34;滑窗&#34;厨师</a>
        <a href="#rnn" class="toc-link block px-4 py-2 text-sm text-gray-600 rounded-md hover:text-charcoal">RNN：依赖记忆的&#34;顺序&#34;厨师</a>
        <a href="#transformer" class="toc-link block px-4 py-2 text-sm text-gray-600 rounded-md hover:text-charcoal">Transformer：全局掌控的&#34;注意力&#34;大师</a>
        <a href="#conclusion" class="toc-link block px-4 py-2 text-sm text-gray-600 rounded-md hover:text-charcoal">总结：三位&#34;厨师&#34;的终极对决</a>
      </nav>
    </div>

    <!-- Main Content -->
    <div class="ml-0 lg:ml-80">
      <!-- Hero Section -->
      <section class="min-h-screen bg-gradient-to-br from-cream via-white to-warm-gray py-16 px-8">
        <div class="max-w-6xl mx-auto">
          <div class="hero-grid">
            <!-- Title -->
            <div class="hero-title text-center mb-12">
              <h1 class="font-serif text-4xl md:text-5xl lg:text-6xl font-bold text-charcoal mb-6 leading-tight break-words">
                神经网络大揭秘
              </h1>
              <p class="font-serif text-xl md:text-2xl lg:text-3xl italic text-sage mb-8 break-words">
                从&#34;厨师&#34;视角趣谈CNN、RNN与Transformer
              </p>
              <div class="w-24 h-1 bg-accent mx-auto"></div>
            </div>

            <!-- Key Highlights -->
            <div class="hero-content space-y-6">
              <div class="bg-white p-6 rounded-lg shadow-md border border-warm-gray">
                <h3 class="font-serif font-bold text-lg text-charcoal mb-3 flex items-center">
                  <i class="fas fa-search-plus text-sage mr-3"></i>
                  CNN - 专注细节的&#34;滑窗&#34;厨师
                </h3>
                <p class="text-gray-700 text-sm leading-relaxed">
                  擅长用&#34;放大镜&#34;（卷积核）在图像上寻找局部特征，通过滑动窗口方式提取边缘、纹理等信息，是图像识别和计算机视觉的行家里手。
                </p>
              </div>

              <div class="bg-white p-6 rounded-lg shadow-md border border-warm-gray">
                <h3 class="font-serif font-bold text-lg text-charcoal mb-3 flex items-center">
                  <i class="fas fa-history text-sage mr-3"></i>
                  RNN - 依赖记忆的&#34;顺序&#34;厨师
                </h3>
                <p class="text-gray-700 text-sm leading-relaxed">
                  拥有&#34;记事本&#34;（隐藏状态），能按顺序处理数据并记住历史信息，在自然语言处理和时间序列分析方面表现出色。
                </p>
              </div>

              <div class="bg-white p-6 rounded-lg shadow-md border border-warm-gray">
                <h3 class="font-serif font-bold text-lg text-charcoal mb-3 flex items-center">
                  <i class="fas fa-eye text-sage mr-3"></i>
                  Transformer - 全局掌控的&#34;注意力&#34;大师
                </h3>
                <p class="text-gray-700 text-sm leading-relaxed">
                  通过自注意力机制一眼看穿所有数据间的关联，并行处理且能捕捉长距离依赖关系，是大语言模型如GPT、BERT的核心架构。
                </p>
              </div>
            </div>

            <!-- Visual Element -->
            <div class="hero-visual">
              <img src="https://kimi-web-img.moonshot.cn/img/cassette.sphdigital.com.sg/649ef6684604c521c0baf76c352fb517c3cfbacf" alt="现代厨房中三位风格各异的厨师在工作" class="w-full h-64 md:h-80 object-cover rounded-lg shadow-lg" size="medium" aspect="wide" style="photo" query="现代厨房 三位厨师" referrerpolicy="no-referrer" data-modified="1" data-score="0.00"/>
            </div>
          </div>
        </div>
      </section>

      <!-- Introduction Section -->
      <section id="introduction" class="section-anchor py-16 px-8 bg-white">
        <div class="max-w-4xl mx-auto">
          <h2 class="font-serif text-4xl font-bold text-charcoal mb-8 border-b-2 border-accent pb-4">
            开场白：三位&#34;厨师&#34;的厨艺秀
          </h2>

          <div class="prose prose-lg max-w-none">
            <h3 class="font-serif text-2xl font-semibold text-charcoal mb-6">算法与厨师的奇妙比喻</h3>
            <p class="mb-6 text-gray-700 leading-relaxed">
              在人工智能的宏伟厨房里，神经网络模型就像是技艺高超的厨师，它们各自拥有独特的&#34;烹饪&#34;哲学和拿手绝活，将原始数据（食材）加工成我们所需的各种智能应用（美味佳肴）<a href="https://www.linkedin.com/pulse/layman-example-cnn-rnn-gan-generative-ai-srinivas-pradeep-s-kkyhe" class="text-sage hover:underline" target="_blank">[1]</a>
              <a href="https://medium.com/@renji.bio/types-of-neural-networks-meet-the-ai-chefs-a-beginners-guide-a41f6673579b" class="text-sage hover:underline" target="_blank">[2]</a>。
            </p>

            <div class="bg-sage/10 p-6 rounded-lg mb-8 border-l-4 border-sage">
              <p class="italic text-gray-700">
                &#34;通过这种拟人化的方式，我们可以将抽象的数学概念和算法逻辑转化为具体的、可感知的烹饪过程。&#34;
              </p>
            </div>

            <h3 class="font-serif text-2xl font-semibold text-charcoal mb-6">三位厨师的&#34;烹饪&#34;风格概览</h3>

            <div class="overflow-x-auto mb-8">
              <table class="w-full border-collapse bg-white rounded-lg shadow-sm">
                <thead class="bg-warm-gray">
                  <tr>
                    <th class="border border-gray-300 px-4 py-3 text-left font-semibold">厨师姓名</th>
                    <th class="border border-gray-300 px-4 py-3 text-left font-semibold">烹饪风格 (核心思想)</th>
                    <th class="border border-gray-300 px-4 py-3 text-left font-semibold">独门绝技 (关键机制)</th>
                    <th class="border border-gray-300 px-4 py-3 text-left font-semibold">拿手好菜 (适用场景)</th>
                  </tr>
                </thead>
                <tbody>
                  <tr class="hover:bg-warm-gray/50">
                    <td class="border border-gray-300 px-4 py-3 font-semibold text-sage">CNN</td>
                    <td class="border border-gray-300 px-4 py-3">专注细节的&#34;滑窗&#34;厨师</td>
                    <td class="border border-gray-300 px-4 py-3">滑动窗口（卷积核）局部感知</td>
                    <td class="border border-gray-300 px-4 py-3">图像识别、计算机视觉</td>
                  </tr>
                  <tr class="hover:bg-warm-gray/50">
                    <td class="border border-gray-300 px-4 py-3 font-semibold text-sage">RNN</td>
                    <td class="border border-gray-300 px-4 py-3">依赖记忆的&#34;顺序&#34;厨师</td>
                    <td class="border border-gray-300 px-4 py-3">&#34;记忆细胞&#34;（隐藏状态）</td>
                    <td class="border border-gray-300 px-4 py-3">自然语言处理、时间序列</td>
                  </tr>
                  <tr class="hover:bg-warm-gray/50">
                    <td class="border border-gray-300 px-4 py-3 font-semibold text-sage">Transformer</td>
                    <td class="border border-gray-300 px-4 py-3">全局掌控的&#34;注意力&#34;大师</td>
                    <td class="border border-gray-300 px-4 py-3">自注意力机制</td>
                    <td class="border border-gray-300 px-4 py-3">机器翻译、大语言模型</td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
        </div>
      </section>

      <!-- CNN Section -->
      <section id="cnn" class="section-anchor py-16 px-8 bg-warm-gray/30">
        <div class="max-w-4xl mx-auto">
          <h2 class="font-serif text-4xl font-bold text-charcoal mb-8 border-b-2 border-accent pb-4">
            CNN：专注细节的&#34;滑窗&#34;厨师
          </h2>

          <div class="prose prose-lg max-w-none">
            <p class="mb-6 text-gray-700 leading-relaxed">
              卷积神经网络（CNN），这位在计算机视觉领域深耕多年的&#34;老厨师&#34;，其核心烹饪哲学可以概括为&#34;于无声处听惊雷，于细微处见真章&#34;。他坚信，复杂的宏观世界是由无数简单的微观模式构成的<a href="https://deepseek.csdn.net/67c4ff752e30c8639009e7b6.html" class="text-sage hover:underline" target="_blank">[3]</a>。
            </p>

            <h3 class="font-serif text-2xl font-semibold text-charcoal mb-6 mt-8">核心思想：通过&#34;滑动窗口&#34;捕捉局部特征</h3>

            <div class="bg-white p-6 rounded-lg shadow-md mb-8">
              <h4 class="font-semibold text-lg text-charcoal mb-4 flex items-center">
                <i class="fas fa-filter text-sage mr-3"></i>
                卷积操作：用&#34;滤镜&#34;看世界
              </h4>
              <p class="mb-4 text-gray-700">
                卷积操作是CNN的&#34;灵魂&#34;，它就像是给图像加上了一层&#34;滤镜&#34;。这个&#34;滤镜&#34;在技术上被称为卷积核（Kernel）或滤波器（Filter）<a href="https://arthurchiao.github.io/blog/cnn-intuitive-explanation-zh/" class="text-sage hover:underline" target="_blank">[4]</a>。
              </p>

              <div class="bg-sage/10 p-4 rounded-lg">
                <h5 class="font-semibold text-charcoal mb-2">关键概念：</h5>
                <ul class="list-disc list-inside space-y-1 text-sm text-gray-700">
                  <li><strong>卷积核 (Kernel/Filter):</strong> 小的权重矩阵，用于提取局部特征</li>
                  <li><strong>步长 (Stride):</strong> 卷积核在图像上滑动的像素距离</li>
                  <li><strong>填充 (Padding):</strong> 在图像边界外填充像素，控制输出尺寸</li>
                  <li><strong>特征图 (Feature Map):</strong> 卷积操作的输出结果</li>
                </ul>
              </div>
            </div>

            <div class="bg-white p-6 rounded-lg shadow-md mb-8">
              <h4 class="font-semibold text-lg text-charcoal mb-4 flex items-center">
                <i class="fas fa-compress text-sage mr-3"></i>
                池化操作：压缩信息，抓住重点
              </h4>
              <p class="text-gray-700">
                池化操作同样使用一个滑动窗口，进行简单的聚合操作，比如取最大值（最大池化）或取平均值（平均池化）<a href="https://blog.csdn.net/Bossfrank/article/details/139777585" class="text-sage hover:underline" target="_blank">[5]</a>。这个过程就像是给高分辨率照片做&#34;缩略&#34;，保留重要信息的同时减小文件大小。
              </p>
            </div>

            <h3 class="font-serif text-2xl font-semibold text-charcoal mb-6">优缺点与适用场景</h3>

            <div class="grid md:grid-cols-2 gap-6 mb-8">
              <div class="bg-green-50 p-6 rounded-lg border-l-4 border-green-400">
                <h4 class="font-semibold text-green-800 mb-3 flex items-center">
                  <i class="fas fa-check-circle mr-2"></i>
                  优点
                </h4>
                <ul class="list-disc list-inside space-y-1 text-sm text-green-700">
                  <li>参数共享，高效提取局部特征</li>
                  <li>具有平移不变性</li>
                  <li>减少参数量，不易过拟合</li>
                </ul>
              </div>

              <div class="bg-red-50 p-6 rounded-lg border-l-4 border-red-400">
                <h4 class="font-semibold text-red-800 mb-3 flex items-center">
                  <i class="fas fa-exclamation-triangle mr-2"></i>
                  缺点
                </h4>
                <ul class="list-disc list-inside space-y-1 text-sm text-red-700">
                  <li>难以捕捉全局信息</li>
                  <li>对空间位置敏感</li>
                  <li>需要大量数据增强</li>
                </ul>
              </div>
            </div>

            <div class="bg-white p-6 rounded-lg shadow-md mb-8">
              <h4 class="font-semibold text-lg text-charcoal mb-4">适用场景</h4>
              <div class="grid md:grid-cols-2 gap-4">
                <div>
                  <h5 class="font-medium text-charcoal mb-2">图像分类</h5>
                  <p class="text-sm text-gray-700">判断图片是猫还是狗，识别手写数字（MNIST数据集）</p>
                </div>
                <div>
                  <h5 class="font-medium text-charcoal mb-2">目标检测</h5>
                  <p class="text-sm text-gray-700">自动驾驶场景中检测行人、车辆和交通标志</p>
                </div>
                <div>
                  <h5 class="font-medium text-charcoal mb-2">图像分割</h5>
                  <p class="text-sm text-gray-700">医学影像中分割出肿瘤区域</p>
                </div>
                <div>
                  <h5 class="font-medium text-charcoal mb-2">人脸识别</h5>
                  <p class="text-sm text-gray-700">安防、支付等领域的身份验证</p>
                </div>
              </div>
            </div>

            <h3 class="font-serif text-2xl font-semibold text-charcoal mb-6">数学原理：卷积运算的矩阵魔法</h3>
            <p class="mb-6 text-gray-700 leading-relaxed">
              CNN的核心操作——卷积，本质上是一系列的矩阵运算。假设我们有一个输入图像矩阵 I 和一个卷积核 K<a href="https://blog.csdn.net/jinking01/article/details/88990531" class="text-sage hover:underline" target="_blank">[6]</a>：
            </p>

            <div class="bg-gray-100 p-6 rounded-lg mb-8 font-mono text-sm">
              <div class="mb-4">
                <strong>O(i, j) = Σ_{m=0}^{k_h-1} Σ_{n=0}^{k_w-1} I(i+m, j+n) * K(m, n) + b</strong>
              </div>
              <div class="text-gray-600">
                <p>其中：Σ 表示求和，I(i+m, j+n) 是输入图像的像素值，K(m, n) 是卷积核的权重值，b 是偏置项。</p>
              </div>
            </div>

            <h3 class="font-serif text-2xl font-semibold text-charcoal mb-6">常见变体：从LeNet到ResNet的进化之路</h3>

            <div class="mermaid-container">
              <div class="mermaid-controls">
                <button class="mermaid-control-btn zoom-in" title="放大">
                  <i class="fas fa-search-plus"></i>
                </button>
                <button class="mermaid-control-btn zoom-out" title="缩小">
                  <i class="fas fa-search-minus"></i>
                </button>
                <button class="mermaid-control-btn reset-zoom" title="重置">
                  <i class="fas fa-expand-arrows-alt"></i>
                </button>
                <button class="mermaid-control-btn fullscreen" title="全屏查看">
                  <i class="fas fa-expand"></i>
                </button>
              </div>
              <div class="mermaid">
                timeline
                title &#34;CNN架构发展历程&#34;

                1998 : &#34;LeNet-5&#34;
                : &#34;手写数字识别&#34;
                : &#34;CNN开山鼻祖&#34;

                2012 : &#34;AlexNet&#34;
                : &#34;ImageNet竞赛获胜&#34;
                : &#34;深度学习热潮&#34;

                2014 : &#34;VGGNet&#34;
                : &#34;更深的网络&#34;
                : &#34;3x3卷积核&#34;

                2015 : &#34;ResNet&#34;
                : &#34;残差连接&#34;
                : &#34;解决梯度消失&#34;
              </div>
            </div>

            <div class="space-y-4 mb-8">
              <div class="bg-blue-50 p-4 rounded-lg">
                <h5 class="font-semibold text-blue-800">LeNet-5 (1998)</h5>
                <p class="text-sm text-blue-700">由Yann LeCun提出，是CNN的开山鼻祖之一，主要用于手写数字识别<a href="https://arthurchiao.github.io/blog/cnn-intuitive-explanation-zh/" class="text-sage hover:underline" target="_blank">[4]</a>。</p>
              </div>
              <div class="bg-green-50 p-4 rounded-lg">
                <h5 class="font-semibold text-green-800">AlexNet (2012)</h5>
                <p class="text-sm text-green-700">在ImageNet图像识别竞赛中一战成名，引发了深度学习的热潮。</p>
              </div>
              <div class="bg-purple-50 p-4 rounded-lg">
                <h5 class="font-semibold text-purple-800">VGGNet (2014)</h5>
                <p class="text-sm text-purple-700">使用更小尺寸的卷积核（3x3）构建更深的网络，证明了深度的重要性。</p>
              </div>
              <div class="bg-orange-50 p-4 rounded-lg">
                <h5 class="font-semibold text-orange-800">ResNet (2015)</h5>
                <p class="text-sm text-orange-700">引入&#34;残差连接&#34;，解决了深度网络的梯度消失问题，可训练超过100层的网络。</p>
              </div>
            </div>

            <h3 class="font-serif text-2xl font-semibold text-charcoal mb-6">动手实践：用PyTorch搭建一个简单的CNN</h3>

            <div class="bg-gray-900 text-green-400 p-6 rounded-lg mb-8 overflow-x-auto">
              <pre class="text-sm"><code>import torch
import torch.nn as nn
import torch.nn.functional as F

class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.fc1 = nn.Linear(in_features=16 * 4 * 4, out_features=120)
        self.fc2 = nn.Linear(in_features=120, out_features=84)
        self.fc3 = nn.Linear(in_features=84, out_features=10)

    def forward(self, x):
        x = self.pool1(F.relu(self.conv1(x)))
        x = self.pool2(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 4 * 4)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x</code></pre>
            </div>

            <div class="bg-blue-50 p-4 rounded-lg">
              <p class="text-sm text-blue-800">
                <strong>代码解析：</strong> 这个简单的CNN模型包含两个卷积层、两个池化层和三个全连接层<a href="https://blog.csdn.net/Bossfrank/article/details/139777585" class="text-sage hover:underline" target="_blank">[5]</a>。通过卷积和池化的组合，模型能够逐步提取图像的特征，最终进行分类预测。
              </p>
            </div>
          </div>
        </div>
      </section>

      <!-- RNN Section -->
      <section id="rnn" class="section-anchor py-16 px-8 bg-white">
        <div class="max-w-4xl mx-auto">
          <h2 class="font-serif text-4xl font-bold text-charcoal mb-8 border-b-2 border-accent pb-4">
            RNN：依赖记忆的&#34;顺序&#34;厨师
          </h2>

          <div class="prose prose-lg max-w-none">
            <p class="mb-6 text-gray-700 leading-relaxed">
              循环神经网络（RNN）的核心思想在于其独特的&#34;循环&#34;结构，这使得它能够有效地处理序列数据，并捕捉序列中的时间依赖关系。就像一个拥有记事本的厨师，每一步操作都考虑到之前的步骤<a href="https://medium.com/@renji.bio/types-of-neural-networks-meet-the-ai-chefs-a-beginners-guide-a41f6673579b" class="text-sage hover:underline" target="_blank">[2]</a>。
            </p>

            <h3 class="font-serif text-2xl font-semibold text-charcoal mb-6 mt-8">核心思想：通过&#34;循环&#34;处理序列数据</h3>

            <div class="bg-gradient-to-r from-sage/10 to-accent/10 p-8 rounded-lg mb-8">
              <h4 class="font-semibold text-lg text-charcoal mb-4 flex items-center">
                <i class="fas fa-sync-alt text-sage mr-3"></i>
                循环结构：记忆过去，影响未来
              </h4>
              <p class="mb-4 text-gray-700">
                RNN的&#34;循环&#34;结构是其区别于其他神经网络的本质特征。网络在每个时间步 t 的输出不仅取决于当前的输入 x_t，还取决于一个从过去传递过来的内部状态，即隐藏状态 h_{t-1}<a href="https://deepseek.csdn.net/67c4ff752e30c8639009e7b6.html" class="text-sage hover:underline" target="_blank">[3]</a>。
              </p>
              <div class="bg-white p-4 rounded border-l-4 border-sage">
                <p class="text-sm italic text-gray-700">
                  &#34;这种&#39;记忆过去，影响未来&#39;的能力，是RNN强大序列建模能力的根源。&#34;
                </p>
              </div>
            </div>

            <div class="bg-white p-6 rounded-lg shadow-md mb-8">
              <h4 class="font-semibold text-lg text-charcoal mb-4 flex items-center">
                <i class="fas fa-brain text-sage mr-3"></i>
                隐藏状态：传递信息的&#34;记忆细胞&#34;
              </h4>
              <p class="mb-4 text-gray-700">
                在RNN中，隐藏状态（Hidden State）扮演着至关重要的角色，它如同一个&#34;记忆细胞&#34;，负责在序列处理过程中传递和存储信息。这个&#34;记忆细胞&#34;的内容是动态更新的<a href="https://cloud.tencent.com/developer/article/2398345" class="text-sage hover:underline" target="_blank">[7]</a>。
              </p>
              <div class="bg-gray-100 p-4 rounded-lg font-mono text-sm">
                <code>h_t = tanh(W_h * h_{t-1} + W_x * x_t + b)</code>
              </div>
            </div>

            <h3 class="font-serif text-2xl font-semibold text-charcoal mb-6">优缺点与适用场景</h3>

            <div class="grid md:grid-cols-2 gap-6 mb-8">
              <div class="bg-green-50 p-6 rounded-lg border-l-4 border-green-400">
                <h4 class="font-semibold text-green-800 mb-3">优点</h4>
                <ul class="list-disc list-inside space-y-1 text-sm text-green-700">
                  <li>能处理序列数据</li>
                  <li>记忆历史信息</li>
                  <li>接受任意长度输入</li>
                </ul>
              </div>

              <div class="bg-red-50 p-6 rounded-lg border-l-4 border-red-400">
                <h4 class="font-semibold text-red-800 mb-3">缺点</h4>
                <ul class="list-disc list-inside space-y-1 text-sm text-red-700">
                  <li>梯度消失/爆炸问题</li>
                  <li>长程依赖能力弱</li>
                  <li>顺序计算效率低</li>
                </ul>
              </div>
            </div>

            <div class="bg-blue-50 p-6 rounded-lg mb-8">
              <h4 class="font-semibold text-blue-800 mb-4">适用场景</h4>
              <div class="grid md:grid-cols-3 gap-4">
                <div class="text-center">
                  <i class="fas fa-language text-2xl text-blue-600 mb-2"></i>
                  <h5 class="font-medium text-blue-800 mb-1">自然语言处理</h5>
                  <p class="text-xs text-blue-700">语言建模、机器翻译、情感分析</p>
                </div>
                <div class="text-center">
                  <i class="fas fa-chart-line text-2xl text-blue-600 mb-2"></i>
                  <h5 class="font-medium text-blue-800 mb-1">时间序列分析</h5>
                  <p class="text-xs text-blue-700">股票价格预测、气象预报</p>
                </div>
                <div class="text-center">
                  <i class="fas fa-microphone text-2xl text-blue-600 mb-2"></i>
                  <h5 class="font-medium text-blue-800 mb-1">语音识别</h5>
                  <p class="text-xs text-blue-700">语音转文本、声纹识别</p>
                </div>
              </div>
            </div>

            <h3 class="font-serif text-2xl font-semibold text-charcoal mb-6">数学原理：递归关系式的展开</h3>
            <p class="mb-6 text-gray-700 leading-relaxed">
              从数学上看，RNN的核心是一个递归关系式。在每个时间步 t，网络的隐藏状态 h_t 和输出 y_t 的计算都依赖于当前输入 x_t 和上一个时间步的隐藏状态 h_{t-1}<a href="https://cloud.tencent.com/developer/article/2398345" class="text-sage hover:underline" target="_blank">[7]</a>：
            </p>

            <div class="bg-gray-100 p-6 rounded-lg mb-8 font-mono text-sm">
              <div class="space-y-2">
                <div>
                  <code>h_t = tanh(W_h * h_{t-1} + W_x * x_t + b_h)</code>
                </div>
                <div>
                  <code>y_t = W_y * h_t + b_y</code>
                </div>
              </div>
            </div>

            <h3 class="font-serif text-2xl font-semibold text-charcoal mb-6">常见变体：LSTM与GRU的诞生</h3>

            <div class="grid md:grid-cols-2 gap-6 mb-8">
              <div class="bg-purple-50 p-6 rounded-lg">
                <h4 class="font-semibold text-purple-800 mb-3 flex items-center">
                  <i class="fas fa-memory text-purple-600 mr-2"></i>
                  LSTM
                </h4>
                <p class="text-sm text-purple-700 mb-3">
                  长短期记忆网络，通过细胞状态和三个门控机制（遗忘门、输入门、输出门）来解决长程依赖问题。
                </p>
                <div class="text-xs text-purple-600">
                  <strong>核心创新：</strong> 细胞状态 + 门控机制
                </div>
              </div>

              <div class="bg-green-50 p-6 rounded-lg">
                <h4 class="font-semibold text-green-800 mb-3 flex items-center">
                  <i class="fas fa-tachometer-alt text-green-600 mr-2"></i>
                  GRU
                </h4>
                <p class="text-sm text-green-700 mb-3">
                  门控循环单元，LSTM的简化版本，将遗忘门和输入门合并为更新门，结构更简单，参数更少。
                </p>
                <div class="text-xs text-green-600">
                  <strong>优势：</strong> 训练速度更快，计算效率更高
                </div>
              </div>
            </div>

            <h3 class="font-serif text-2xl font-semibold text-charcoal mb-6">动手实践：用PyTorch搭建一个简单的RNN</h3>

            <div class="bg-gray-900 text-green-400 p-6 rounded-lg mb-8 overflow-x-auto">
              <pre class="text-sm"><code>import torch
import torch.nn as nn

class SimpleRNN(nn.Module):
    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim, num_layers=1):
        super(SimpleRNN, self).__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim)
        self.rnn = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        embedded = self.embedding(x)
        out, (hidden, cell) = self.rnn(embedded)
        sentence_rep = out[:, -1, :]
        output = self.fc(sentence_rep)
        return output</code></pre>
            </div>

            <div class="bg-yellow-50 p-4 rounded-lg">
              <p class="text-sm text-yellow-800">
                <strong>应用场景：</strong> 这个简单的RNN模型可以用于文本分类任务，例如对IMDB电影评论进行情感分析<a href="https://blog.csdn.net/Gupao123/article/details/148081813" class="text-sage hover:underline" target="_blank">[8]</a>。
              </p>
            </div>
          </div>
        </div>
      </section>

      <!-- Transformer Section -->
      <section id="transformer" class="section-anchor py-16 px-8 bg-warm-gray/30">
        <div class="max-w-4xl mx-auto">
          <h2 class="font-serif text-4xl font-bold text-charcoal mb-8 border-b-2 border-accent pb-4">
            Transformer：全局掌控的&#34;注意力&#34;大师
          </h2>

          <div class="prose prose-lg max-w-none">
            <p class="mb-6 text-gray-700 leading-relaxed">
              Transformer模型的核心思想，在于它彻底颠覆了传统序列模型处理信息的方式，引入了一种名为&#34;自注意力机制&#34;的强大工具，从而实现了对输入序列的全局掌控<a href="https://medium.com/@renji.bio/types-of-neural-networks-meet-the-ai-chefs-a-beginners-guide-a41f6673579b" class="text-sage hover:underline" target="_blank">[2]</a>。
            </p>

            <h3 class="font-serif text-2xl font-semibold text-charcoal mb-6 mt-8">核心思想：用&#34;自注意力&#34;机制颠覆传统</h3>

            <div class="bg-gradient-to-br from-sage/20 to-accent/20 p-8 rounded-lg mb-8">
              <h4 class="font-semibold text-lg text-charcoal mb-4 flex items-center">
                <i class="fas fa-eye text-sage mr-3"></i>
                自注意力机制：关注全局，忽略无关
              </h4>
              <p class="mb-4 text-gray-700">
                自注意力机制赋予了模型一种前所未有的能力：在处理序列中的任何一个元素时，都能够&#34;关注全局，忽略无关&#34;。当模型处理一个单词时，会计算这个单词与句子中所有其他单词之间的&#34;注意力分数&#34;。
              </p>
              <div class="bg-white/70 p-4 rounded border-l-4 border-sage">
                <p class="text-sm italic text-gray-700">
                  &#34;在理解句子&#39;The cat, which was very fluffy, sat on the mat&#39;中的&#39;it&#39;指代什么时，自注意力机制会给&#39;cat&#39;这个词分配很高的注意力权重。&#34;
                </p>
              </div>
            </div>

            <div class="bg-white p-6 rounded-lg shadow-md mb-8">
              <h4 class="font-semibold text-lg text-charcoal mb-4 flex items-center">
                <i class="fas fa-parallel text-sage mr-3"></i>
                并行计算：告别顺序处理的效率瓶颈
              </h4>
              <p class="mb-4 text-gray-700">
                Transformer的自注意力机制从根本上改变了RNN的顺序处理瓶颈。所有位置的注意力计算都可以同时进行，无需等待<a href="https://cloud.tencent.com/developer/article/2387288" class="text-sage hover:underline" target="_blank">[9]</a>。
              </p>
              <div class="grid md:grid-cols-2 gap-4">
                <div class="bg-red-50 p-4 rounded">
                  <h5 class="font-medium text-red-800 mb-2">RNN</h5>
                  <p class="text-sm text-red-700">顺序处理，计算复杂度 O(n)</p>
                </div>
                <div class="bg-green-50 p-4 rounded">
                  <h5 class="font-medium text-green-800 mb-2">Transformer</h5>
                  <p class="text-sm text-green-700">并行处理，高度可并行化</p>
                </div>
              </div>
            </div>

            <div class="bg-white p-6 rounded-lg shadow-md mb-8">
              <h4 class="font-semibold text-lg text-charcoal mb-4 flex items-center">
                <i class="fas fa-map-marker-alt text-sage mr-3"></i>
                位置编码：为序列注入位置信息
              </h4>
              <p class="mb-4 text-gray-700">
                自注意力机制本身并不包含关于序列中元素位置或顺序的信息。为了解决这个问题，Transformer引入了位置编码机制，为每个输入嵌入注入位置信息<a href="https://blog.csdn.net/yyaannnnnnnn/article/details/128652310" class="text-sage hover:underline" target="_blank">[10]</a>。
              </p>
              <div class="bg-yellow-50 p-4 rounded">
                <p class="text-sm text-yellow-800">
                  <strong>设计原理：</strong> 使用不同频率的正弦和余弦函数来生成位置编码，使得模型能够同时感知绝对位置和相对位置关系。
                </p>
              </div>
            </div>

            <h3 class="font-serif text-2xl font-semibold text-charcoal mb-6">优缺点与适用场景</h3>

            <div class="grid md:grid-cols-2 gap-6 mb-8">
              <div class="bg-green-50 p-6 rounded-lg border-l-4 border-green-400">
                <h4 class="font-semibold text-green-800 mb-3">优点</h4>
                <ul class="list-disc list-inside space-y-1 text-sm text-green-700">
                  <li>强大的长距离依赖捕捉能力</li>
                  <li>并行计算效率高</li>
                  <li>可扩展性强</li>
                  <li>全局上下文理解出色</li>
                </ul>
              </div>

              <div class="bg-red-50 p-6 rounded-lg border-l-4 border-red-400">
                <h4 class="font-semibold text-red-800 mb-3">缺点</h4>
                <ul class="list-disc list-inside space-y-1 text-sm text-red-700">
                  <li>计算复杂度高 O(n²)</li>
                  <li>需要海量数据训练</li>
                  <li>局部信息捕捉能力相对较弱</li>
                  <li>内存消耗大</li>
                </ul>
              </div>
            </div>

            <div class="bg-white p-6 rounded-lg shadow-md mb-8">
              <h4 class="font-semibold text-lg text-charcoal mb-4">适用场景</h4>
              <div class="grid md:grid-cols-3 gap-4">
                <div class="text-center p-4 bg-blue-50 rounded">
                  <i class="fas fa-language text-2xl text-blue-600 mb-2"></i>
                  <h5 class="font-medium text-blue-800 mb-1">机器翻译</h5>
                  <p class="text-xs text-blue-700">跨语言文本转换</p>
                </div>
                <div class="text-center p-4 bg-green-50 rounded">
                  <i class="fas fa-pen-fancy text-2xl text-green-600 mb-2"></i>
                  <h5 class="font-medium text-green-800 mb-1">文本生成</h5>
                  <p class="text-xs text-green-700">对话系统、故事创作</p>
                </div>
                <div class="text-center p-4 bg-purple-50 rounded">
                  <i class="fas fa-brain text-2xl text-purple-600 mb-2"></i>
                  <h5 class="font-medium text-purple-800 mb-1">大语言模型</h5>
                  <p class="text-xs text-purple-700">GPT、BERT等预训练模型</p>
                </div>
              </div>
            </div>

            <h3 class="font-serif text-2xl font-semibold text-charcoal mb-6">数学原理：Q、K、V的矩阵舞蹈</h3>
            <p class="mb-6 text-gray-700 leading-relaxed">
              Transformer的自注意力机制，其核心数学原理可以精妙地概括为一场由查询（Query, Q）、键（Key, K）和值（Value, V）三个矩阵共同参与的&#34;矩阵舞蹈&#34;<a href="https://www.cnblogs.com/rossiXYZ/p/18751758" class="text-sage hover:underline" target="_blank">[11]</a>。
            </p>

            <div class="bg-gray-100 p-6 rounded-lg mb-8 font-mono text-sm">
              <div class="space-y-3">
                <div>
                  <strong>1. Q、K、V矩阵生成：</strong>
                  <br/>
                  <code>Q = X * W_Q, K = X * W_K, V = X * W_V</code>
                </div>
                <div>
                  <strong>2. 注意力分数计算：</strong>
                  <br/>
                  <code>Scores = (Q * K^T) / sqrt(d_k)</code>
                </div>
                <div>
                  <strong>3. Softmax归一化：</strong>
                  <br/>
                  <code>Attention Weights = softmax(Scores, dim=-1)</code>
                </div>
                <div>
                  <strong>4. 加权求和输出：</strong>
                  <br/>
                  <code>Output = Attention Weights * V</code>
                </div>
              </div>
            </div>

            <h3 class="font-serif text-2xl font-semibold text-charcoal mb-6">常见变体：BERT与GPT的双雄争霸</h3>

            <div class="grid md:grid-cols-2 gap-6 mb-8">
              <div class="bg-blue-50 p-6 rounded-lg border-l-4 border-blue-400">
                <h4 class="font-semibold text-blue-800 mb-3 flex items-center">
                  <i class="fas fa-book-reader text-blue-600 mr-2"></i>
                  BERT
                </h4>
                <p class="text-sm text-blue-700 mb-3">
                  基于Transformer编码器，采用双向预训练策略，通过掩码语言模型任务学习上下文表示。
                </p>
                <div class="text-xs text-blue-600">
                  <strong>特点：</strong> 双向理解，擅长自然语言理解任务
                </div>
              </div>

              <div class="bg-green-50 p-6 rounded-lg border-l-4 border-green-400">
                <h4 class="font-semibold text-green-800 mb-3 flex items-center">
                  <i class="fas fa-pen text-green-600 mr-2"></i>
                  GPT
                </h4>
                <p class="text-sm text-green-700 mb-3">
                  基于Transformer解码器，采用自回归预训练策略，根据前面的单词预测下一个单词。
                </p>
                <div class="text-xs text-green-600">
                  <strong>特点：</strong> 自回归生成，擅长文本生成任务
                </div>
              </div>
            </div>

            <h3 class="font-serif text-2xl font-semibold text-charcoal mb-6">动手实践：用PyTorch搭建一个简单的Transformer</h3>

            <div class="bg-gray-900 text-green-400 p-6 rounded-lg mb-8 overflow-x-auto">
              <pre class="text-sm"><code>import torch
import torch.nn as nn
import math

class PositionalEncoding(nn.Module):
    def __init__(self, d_model, max_len=5000):
        super(PositionalEncoding, self).__init__()
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0).transpose(0, 1)
        self.register_buffer(&#39;pe&#39;, pe)

    def forward(self, x):
        return x + self.pe[:x.size(0), :]

class SimpleTransformer(nn.Module):
    def __init__(self, vocab_size, d_model=512, nhead=8, num_layers=6, dim_feedforward=2048, num_classes=2):
        super(SimpleTransformer, self).__init__()
        self.d_model = d_model
        self.embedding = nn.Embedding(vocab_size, d_model)
        self.pos_encoder = PositionalEncoding(d_model)
        
        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward)
        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        
        self.fc = nn.Linear(d_model, num_classes)

    def forward(self, src):
        src = src.transpose(0, 1)
        embedded = self.embedding(src) * math.sqrt(self.d_model)
        embedded = self.pos_encoder(embedded)
        
        output = self.transformer_encoder(embedded)
        output = output[-1, :, :]
        output = self.fc(output)
        return output</code></pre>
            </div>

            <div class="bg-green-50 p-4 rounded-lg">
              <p class="text-sm text-green-800">
                <strong>应用场景：</strong> 这个简单的Transformer模型可以用于文本分类、情感分析等自然语言理解任务<a href="https://developer.aliyun.com/article/1487366" class="text-sage hover:underline" target="_blank">[12]</a>。
              </p>
            </div>
          </div>
        </div>
      </section>

      <!-- Conclusion Section -->
      <section id="conclusion" class="section-anchor py-16 px-8 bg-white">
        <div class="max-w-4xl mx-auto">
          <h2 class="font-serif text-4xl font-bold text-charcoal mb-8 border-b-2 border-accent pb-4">
            总结：三位&#34;厨师&#34;的终极对决
          </h2>

          <div class="prose prose-lg max-w-none">
            <h3 class="font-serif text-2xl font-semibold text-charcoal mb-6">核心思想对比：局部、顺序与全局</h3>

            <div class="grid md:grid-cols-3 gap-6 mb-8">
              <div class="bg-yellow-50 p-6 rounded-lg text-center border-2 border-yellow-200">
                <div class="w-16 h-16 bg-yellow-200 rounded-full flex items-center justify-center mx-auto mb-4">
                  <i class="fas fa-search-plus text-2xl text-yellow-800"></i>
                </div>
                <h4 class="font-semibold text-yellow-800 mb-3">CNN</h4>
                <p class="text-sm text-yellow-700 mb-3">&#34;滑窗&#34;厨师</p>
                <p class="text-xs text-yellow-600">专注局部特征提取</p>
              </div>

              <div class="bg-blue-50 p-6 rounded-lg text-center border-2 border-blue-200">
                <div class="w-16 h-16 bg-blue-200 rounded-full flex items-center justify-center mx-auto mb-4">
                  <i class="fas fa-history text-2xl text-blue-800"></i>
                </div>
                <h4 class="font-semibold text-blue-800 mb-3">RNN</h4>
                <p class="text-sm text-blue-700 mb-3">&#34;顺序&#34;厨师</p>
                <p class="text-xs text-blue-600">依赖顺序记忆处理</p>
              </div>

              <div class="bg-green-50 p-6 rounded-lg text-center border-2 border-green-200">
                <div class="w-16 h-16 bg-green-200 rounded-full flex items-center justify-center mx-auto mb-4">
                  <i class="fas fa-eye text-2xl text-green-800"></i>
                </div>
                <h4 class="font-semibold text-green-800 mb-3">Transformer</h4>
                <p class="text-sm text-green-700 mb-3">&#34;注意力&#34;大师</p>
                <p class="text-xs text-green-600">全局注意力掌控</p>
              </div>
            </div>

            <p class="mb-6 text-gray-700 leading-relaxed">
              这三种思想分别代表了深度学习在处理不同数据类型时的三种主流范式：局部感知、顺序记忆和全局关注<a href="http://www.360doc.com/content/24/0707/06/21539921_1128151622.shtml" class="text-sage hover:underline" target="_blank">[13]</a>。
            </p>

            <h3 class="font-serif text-2xl font-semibold text-charcoal mb-6">适用场景对比：图像、序列与语言</h3>

            <div class="overflow-x-auto mb-8">
              <table class="w-full border-collapse bg-white rounded-lg shadow-sm">
                <thead class="bg-warm-gray">
                  <tr>
                    <th class="border border-gray-300 px-4 py-3 text-left font-semibold">模型</th>
                    <th class="border border-gray-300 px-4 py-3 text-left font-semibold">核心优势</th>
                    <th class="border border-gray-300 px-4 py-3 text-left font-semibold">主要应用领域</th>
                    <th class="border border-gray-300 px-4 py-3 text-left font-semibold">典型应用</th>
                  </tr>
                </thead>
                <tbody>
                  <tr class="hover:bg-warm-gray/50">
                    <td class="border border-gray-300 px-4 py-3 font-semibold text-yellow-600">CNN</td>
                    <td class="border border-gray-300 px-4 py-3">空间特征提取</td>
                    <td class="border border-gray-300 px-4 py-3">计算机视觉</td>
                    <td class="border border-gray-300 px-4 py-3">图像分类、目标检测</td>
                  </tr>
                  <tr class="hover:bg-warm-gray/50">
                    <td class="border border-gray-300 px-4 py-3 font-semibold text-blue-600">RNN</td>
                    <td class="border border-gray-300 px-4 py-3">时序建模</td>
                    <td class="border border-gray-300 px-4 py-3">序列数据处理</td>
                    <td class="border border-gray-300 px-4 py-3">时间序列预测、语音识别</td>
                  </tr>
                  <tr class="hover:bg-warm-gray/50">
                    <td class="border border-gray-300 px-4 py-3 font-semibold text-green-600">Transformer</td>
                    <td class="border border-gray-300 px-4 py-3">全局依赖建模</td>
                    <td class="border border-gray-300 px-4 py-3">自然语言处理</td>
                    <td class="border border-gray-300 px-4 py-3">机器翻译、大语言模型</td>
                  </tr>
                </tbody>
              </table>
            </div>

            <h3 class="font-serif text-2xl font-semibold text-charcoal mb-6">未来展望：算法融合与新星崛起</h3>

            <div class="bg-gradient-to-r from-sage/10 to-accent/10 p-8 rounded-lg mb-8">
              <p class="mb-4 text-gray-700">
                尽管Transformer在当前阶段展现出了强大的统治力，但这并不意味着CNN和RNN将被完全取代。未来的发展趋势更可能是不同模型架构的融合与互补<a href="https://blog.csdn.net/xidianjiapei001/article/details/146101695" class="text-sage hover:underline" target="_blank">[14]</a>。
              </p>

              <div class="grid md:grid-cols-2 gap-4">
                <div class="bg-white/70 p-4 rounded">
                  <h5 class="font-medium text-charcoal mb-2 flex items-center">
                    <i class="fas fa-puzzle-piece text-sage mr-2"></i>
                    算法融合
                  </h5>
                  <p class="text-sm text-gray-700">
                    CNN的局部感知优势与Transformer的全局建模能力相结合，构建更强大的视觉模型。
                  </p>
                </div>
                <div class="bg-white/70 p-4 rounded">
                  <h5 class="font-medium text-charcoal mb-2 flex items-center">
                    <i class="fas fa-rocket text-sage mr-2"></i>
                    新星崛起
                  </h5>
                  <p class="text-sm text-gray-700">
                    状态空间模型（SSMs）如Mamba等新兴架构，试图在保持线性计算复杂度的同时实现高效的长程依赖建模。
                  </p>
                </div>
              </div>
            </div>

            <div class="bg-sage/10 p-6 rounded-lg border-l-4 border-sage">
              <p class="italic text-gray-700 text-center">
                &#34;未来的AI厨房，将不再是几位&#39;大厨&#39;的独角戏，而更像是一场百花齐放的&#39;厨艺大赛&#39;，各种新旧&#39;厨师&#39;将同台竞技，共同推动人工智能技术的边界不断向前拓展。&#34;
              </p>
            </div>
          </div>
        </div>
      </section>

      <!-- Footer -->
      <footer class="bg-charcoal text-white py-8 px-8">
        <div class="max-w-4xl mx-auto text-center">
          <p class="text-sm opacity-75">
            通过生动有趣的&#34;厨师&#34;比喻，我们从零开始探索了CNN、RNN和Transformer这三种核心神经网络算法。希望这份&#34;算法大餐&#34;能帮助您更好地理解人工智能的精髓。
          </p>
          <div class="mt-4">
            <p class="text-xs opacity-50">
              参考资料来源：CSDN、博客园、腾讯云、LinkedIn、Medium等技术社区
            </p>
          </div>
        </div>
      </footer>
    </div>

    <script>
        // Initialize Mermaid with custom theme and configuration
        mermaid.initialize({ 
            startOnLoad: true, 
            theme: 'base',
            themeVariables: {
                // Primary colors with good contrast
                primaryColor: '#ffffff',
                primaryTextColor: '#2D3436',
                primaryBorderColor: '#2D3436',
                lineColor: '#9CAF88',
                
                // Secondary colors
                secondaryColor: '#f8f9fa',
                secondaryTextColor: '#2D3436',
                secondaryBorderColor: '#9CAF88',
                
                // Tertiary colors
                tertiaryColor: '#e9ecef',
                tertiaryTextColor: '#2D3436',
                tertiaryBorderColor: '#9CAF88',
                
                // Background and text
                background: '#ffffff',
                mainBkg: '#ffffff',
                secondBkg: '#f8f9fa',
                tertiaryBkg: '#e9ecef',
                
                // Text colors for better contrast
                textColor: '#2D3436',
                nodeTextColor: '#2D3436',
                
                // Timeline specific colors
                cScale0: '#ffffff',
                cScale1: '#f8f9fa',
                cScale2: '#e9ecef',
                
                // Ensure all text is dark for readability
                darkTextColor: '#2D3436',
                taskBkgColor: '#ffffff',
                taskTextColor: '#2D3436',
                taskTextOutsideColor: '#2D3436',
                activeTaskBkgColor: '#f8f9fa',
                activeTaskBorderColor: '#9CAF88',
                
                // Grid and axis
                gridColor: '#e9ecef',
                section0: '#ffffff',
                section1: '#f8f9fa',
                section2: '#e9ecef',
                section3: '#dee2e6'
            },
            timeline: {
                numberSectionStyles: 4,
                axisFormat: '%Y',
                useMaxWidth: true,
                padding: 20
            },
            flowchart: {
                useMaxWidth: true,
                htmlLabels: true
            },
            sequence: {
                useMaxWidth: true
            }
        });

        // Initialize Mermaid Controls for zoom and pan
        function initializeMermaidControls() {
            const containers = document.querySelectorAll('.mermaid-container');

            containers.forEach(container => {
            const mermaidElement = container.querySelector('.mermaid');
            let scale = 1;
            let isDragging = false;
            let startX, startY, translateX = 0, translateY = 0;

            // 触摸相关状态
            let isTouch = false;
            let touchStartTime = 0;
            let initialDistance = 0;
            let initialScale = 1;
            let isPinching = false;

            // Zoom controls
            const zoomInBtn = container.querySelector('.zoom-in');
            const zoomOutBtn = container.querySelector('.zoom-out');
            const resetBtn = container.querySelector('.reset-zoom');
            const fullscreenBtn = container.querySelector('.fullscreen');

            function updateTransform() {
                mermaidElement.style.transform = `translate(${translateX}px, ${translateY}px) scale(${scale})`;

                if (scale > 1) {
                container.classList.add('zoomed');
                } else {
                container.classList.remove('zoomed');
                }

                mermaidElement.style.cursor = isDragging ? 'grabbing' : 'grab';
            }

            if (zoomInBtn) {
                zoomInBtn.addEventListener('click', () => {
                scale = Math.min(scale * 1.25, 4);
                updateTransform();
                });
            }

            if (zoomOutBtn) {
                zoomOutBtn.addEventListener('click', () => {
                scale = Math.max(scale / 1.25, 0.3);
                if (scale <= 1) {
                    translateX = 0;
                    translateY = 0;
                }
                updateTransform();
                });
            }

            if (resetBtn) {
                resetBtn.addEventListener('click', () => {
                scale = 1;
                translateX = 0;
                translateY = 0;
                updateTransform();
                });
            }

            if (fullscreenBtn) {
                fullscreenBtn.addEventListener('click', () => {
                if (container.requestFullscreen) {
                    container.requestFullscreen();
                } else if (container.webkitRequestFullscreen) {
                    container.webkitRequestFullscreen();
                } else if (container.msRequestFullscreen) {
                    container.msRequestFullscreen();
                }
                });
            }

            // Mouse Events
            mermaidElement.addEventListener('mousedown', (e) => {
                if (isTouch) return; // 如果是触摸设备，忽略鼠标事件

                isDragging = true;
                startX = e.clientX - translateX;
                startY = e.clientY - translateY;
                mermaidElement.style.cursor = 'grabbing';
                updateTransform();
                e.preventDefault();
            });

            document.addEventListener('mousemove', (e) => {
                if (isDragging && !isTouch) {
                translateX = e.clientX - startX;
                translateY = e.clientY - startY;
                updateTransform();
                }
            });

            document.addEventListener('mouseup', () => {
                if (isDragging && !isTouch) {
                isDragging = false;
                mermaidElement.style.cursor = 'grab';
                updateTransform();
                }
            });

            document.addEventListener('mouseleave', () => {
                if (isDragging && !isTouch) {
                isDragging = false;
                mermaidElement.style.cursor = 'grab';
                updateTransform();
                }
            });

            // 获取两点之间的距离
            function getTouchDistance(touch1, touch2) {
                return Math.hypot(
                touch2.clientX - touch1.clientX,
                touch2.clientY - touch1.clientY
                );
            }

            // Touch Events - 触摸事件处理
            mermaidElement.addEventListener('touchstart', (e) => {
                isTouch = true;
                touchStartTime = Date.now();

                if (e.touches.length === 1) {
                // 单指拖动
                isPinching = false;
                isDragging = true;

                const touch = e.touches[0];
                startX = touch.clientX - translateX;
                startY = touch.clientY - translateY;

                } else if (e.touches.length === 2) {
                // 双指缩放
                isPinching = true;
                isDragging = false;

                const touch1 = e.touches[0];
                const touch2 = e.touches[1];
                initialDistance = getTouchDistance(touch1, touch2);
                initialScale = scale;
                }

                e.preventDefault();
            }, { passive: false });

            mermaidElement.addEventListener('touchmove', (e) => {
                if (e.touches.length === 1 && isDragging && !isPinching) {
                // 单指拖动
                const touch = e.touches[0];
                translateX = touch.clientX - startX;
                translateY = touch.clientY - startY;
                updateTransform();

                } else if (e.touches.length === 2 && isPinching) {
                // 双指缩放
                const touch1 = e.touches[0];
                const touch2 = e.touches[1];
                const currentDistance = getTouchDistance(touch1, touch2);

                if (initialDistance > 0) {
                    const newScale = Math.min(Math.max(
                    initialScale * (currentDistance / initialDistance),
                    0.3
                    ), 4);
                    scale = newScale;
                    updateTransform();
                }
                }

                e.preventDefault();
            }, { passive: false });

            mermaidElement.addEventListener('touchend', (e) => {
                // 重置状态
                if (e.touches.length === 0) {
                isDragging = false;
                isPinching = false;
                initialDistance = 0;

                // 延迟重置isTouch，避免鼠标事件立即触发
                setTimeout(() => {
                    isTouch = false;
                }, 100);
                } else if (e.touches.length === 1 && isPinching) {
                // 从双指变为单指，切换为拖动模式
                isPinching = false;
                isDragging = true;

                const touch = e.touches[0];
                startX = touch.clientX - translateX;
                startY = touch.clientY - translateY;
                }

                updateTransform();
            });

            mermaidElement.addEventListener('touchcancel', (e) => {
                isDragging = false;
                isPinching = false;
                initialDistance = 0;

                setTimeout(() => {
                isTouch = false;
                }, 100);

                updateTransform();
            });

            // Enhanced wheel zoom with better center point handling
            container.addEventListener('wheel', (e) => {
                e.preventDefault();
                const rect = container.getBoundingClientRect();
                const centerX = rect.width / 2;
                const centerY = rect.height / 2;

                const delta = e.deltaY > 0 ? 0.9 : 1.1;
                const newScale = Math.min(Math.max(scale * delta, 0.3), 4);

                // Adjust translation to zoom towards center
                if (newScale !== scale) {
                const scaleDiff = newScale / scale;
                translateX = translateX * scaleDiff;
                translateY = translateY * scaleDiff;
                scale = newScale;

                if (scale <= 1) {
                    translateX = 0;
                    translateY = 0;
                }

                updateTransform();
                }
            });

            // Initialize display
            updateTransform();
            });
        }

        document.addEventListener('DOMContentLoaded', function() {
            initializeMermaidControls();
        });

        // Smooth scrolling for TOC links
        document.querySelectorAll('.toc-link').forEach(link => {
            link.addEventListener('click', function(e) {
                e.preventDefault();
                const targetId = this.getAttribute('href').substring(1);
                const targetElement = document.getElementById(targetId);
                if (targetElement) {
                    targetElement.scrollIntoView({
                        behavior: 'smooth',
                        block: 'start'
                    });
                }
            });
        });

        // Active TOC link highlighting
        function updateActiveTocLink() {
            const sections = document.querySelectorAll('.section-anchor');
            const tocLinks = document.querySelectorAll('.toc-link');
            
            let currentSection = '';
            sections.forEach(section => {
                const rect = section.getBoundingClientRect();
                if (rect.top <= 120 && rect.bottom >= 120) {
                    currentSection = section.id;
                }
            });

            tocLinks.forEach(link => {
                link.classList.remove('active');
                if (link.getAttribute('href') === '#' + currentSection) {
                    link.classList.add('active');
                }
            });
        }

        // Update active TOC link on scroll
        window.addEventListener('scroll', updateActiveTocLink);
        // Initial call
        updateActiveTocLink();
    </script>
  

</body></html>
