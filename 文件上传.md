# 前端文件上传思路

## 大文件上传

### 前端

前端大文件上传的核心是利用`Blob.prototype.slice`方法，文件的 slice 方法可以返回`源文件的某个切片`

**Blob.prototype.slice 详解：**

Blob 接口的 slice()方法创建并返回一个新的 Blob 对象，该对象包含调用它的 blob 的子集中的数据

预先定义好单个切片的大小，将文件切分为一个个切片，然后借助 http 的可并发性同时上传多个切片，原本的大文件
变成了多个小的切片文件，可以减少上传时间，还需要给每个切片记录顺序

### 服务端

负责接收前端传输的切片，并在接收到所有切片后`合并`所有切片

这里又引伸出两个问题：

1.何时合并切片，即切片什么时候传输完成。

2.如何合并切片

第一个问题需要前端配合，前端在每个切片中都携带切片最大数量的信息，当服务端接受到这个数量的切片时自动合并
或者也可以额外发一个请求，主动通知服务端进行切片的合并。

第二个问题，具体如何合并切片呢？这里可以使用 Nodejs 的`读写流`将所有切片的流传输到最终文件的流里
下面是代码部分：

### 前端部分：

#### 上传控件

```
<template>
    <div>
        <imput type="file" @change="handleFileChange" />
        <el-button @click="handleUpload">upload</el-button>
    </div>
</template>

<script>
export default {
    data: () => ({
        container: {
            file: null
        }
    }),
    methods: {
        handleFileChange(e) {
            const [file] = e.target.files
            if(!file) return
            Object.assign(this.$data, this.$options.data())
            this.container.file = file
        },
        async handleUpload(){}
    }
}
</script>
```

#### 请求逻辑

```
request({
    url, // 本次想访问的接口地址
    method = "post", // 方法
    data, // 请求体
    headers = {}, // 请求头
    requestList //外部数组
    }) {
        return Promise(resolve => {
            const xhr = new XMLHttpRequest()
            xhr.open(method, url) // 初始化连接
            Object.keys(headers).forEach(key =>
                xhr.setRequestHeader(key, headers[key])
            ) // 遍历用户传进来的头信息，逐个塞给XHR的
            xhr.send(data)
            xhr.onload = e => {
                resolve({
                    data: e.target.response
                })
            }
        })
    }
```

#### 上传切片

· 对文件进行切片
· 将切片传输给服务端

```
<template>
  <div>
    <input type="file" @change="handleFileChange" />
    <el-button @click="handleUpload">上传</el-button>
  </div>
</template>
​
<script>
+ // 切片大小
+ // the chunk size
+ const SIZE = 10 * 1024 * 1024;
​
export default {
  data: () => ({
    container: {
      file: null
    }，
+   data: []
  }),
  methods: {
    request() {},
    handleFileChange() {},
+    // 生成文件切片
+    createFileChunk(file, size = SIZE) {
+     const fileChunkList = [];
+      let cur = 0;
+      while (cur < file.size) {
+        fileChunkList.push({ file: file.slice(cur, cur + size) });
+        cur += size;
+      }
+      return fileChunkList;
+    },
+   // 上传切片
+    async uploadChunks() {
+      const requestList = this.data
+        .map(({ chunk，hash }) => {
+          const formData = new FormData();
+          formData.append("chunk", chunk);
+          formData.append("hash", hash);
+          formData.append("filename", this.container.file.name);
+          return { formData };
+        })
+        .map(({ formData }) =>
+          this.request({
+            url: "http://localhost:3000",
+            data: formData
+          })
+        );
+      // 并发请求
+      await Promise.all(requestList);
+    },
+    async handleUpload() {
+      if (!this.container.file) return;
+      const fileChunkList = this.createFileChunk(this.container.file);
+      this.data = fileChunkList.map(({ file }，index) => ({
+        chunk: file,
+        // 文件名 + 数组下标
+        hash: this.container.file.name + "-" + index
+      }));
+      await this.uploadChunks();
+    }
  }
};
</script>

```

当点击上传按钮时，调用 createFileChunk 将文件切片，切片数量通过文件大小控制，这里设置 10MB，也就是说一个 100 MB 的文件会被分成 10 个 10MB 的切片

createFileChunk 内使用 while 循环和 slice 方法将切片放入 fileChunkList 数组中返回
在生成文件切片时，需要给每个切片一个标识作为 hash，这里暂时使用文件名 + 下标，这样后端可以知道当前切片是第几个切片，用于之后的合并切片

随后调用 uploadChunks 上传所有的文件切片，将文件切片，切片 hash，以及文件名放入 formData 中，再调用上一步的 request 函数返回一个 proimise，最后调用 Promise.all 并发上传所有的切片

#### 发送和并请求

```
添加
await this.mergeRequest();
async mergeRequest() {
    await this.request({
        url: "http://localhost:3000/merge",
        headers: {
            "content-type": "application/json"
        },
        data: JSON.stringify({
            filename: this.container.file.name
        })
    })
}
```

### 服务端部分

使用 http 模块搭建一个简单服务端

```
const http = require("http")
const server = http.createServer()

server.on("request", async(req,res) => {
    res.setHeader("Access-Control-Allow-Origin", "*");
    res.setHeader("Access-Control-Allow-Headers", "*");
    if(req.method === "OPTIONS") {
        res.status = 200
        res.end()
        return
    }
})

server.listen(3000, () => console.log("listening port 3000"))
```

#### 接收切片

```
const http = require("http");
const path = require("path");
+ const fse = require("fs-extra");
+ const multiparty = require("multiparty");
​
const server = http.createServer();
+ // 大文件存储目录
+ const UPLOAD_DIR = path.resolve(__dirname, "..", "target");
​
server.on("request", async (req, res) => {
  res.setHeader("Access-Control-Allow-Origin", "*");
  res.setHeader("Access-Control-Allow-Headers", "*");
  if (req.method === "OPTIONS") {
    res.status = 200;
    res.end();
    return;
  }
​
+  const multipart = new multiparty.Form();
​
+  multipart.parse(req, async (err, fields, files) => {
+    if (err) {
+      return;
+    }
+    const [chunk] = files.chunk;
+    const [hash] = fields.hash;
+    const [filename] = fields.filename;
+    // 创建临时文件夹用于临时存储 chunk
+    // 添加 chunkDir 前缀与文件名做区分
+    const chunkDir = path.resolve(UPLOAD_DIR, 'chunkDir' + filename);
​
+    if (!fse.existsSync(chunkDir)) {
+      await fse.mkdirs(chunkDir);
+    }
​
+    // fs-extra 的 rename 方法 windows 平台会有权限问题
+    // @see https://github.com/meteor/meteor/issues/7852#issuecomment-255767835
+    await fse.move(chunk.path, `${chunkDir}/${hash}`);
+    res.end("received file chunk");
+  });
});
​
server.listen(3000, () => console.log("listening port 3000"));

```

#### 合并切片

```
const http = require("http");
const path = require("path");
const fse = require("fs-extra");
​
const server = http.createServer();
const UPLOAD_DIR = path.resolve(__dirname, "..", "target");
​
+ const resolvePost = req =>
+   new Promise(resolve => {
+     let chunk = "";
+     req.on("data", data => {
+       chunk += data;
+     });
+     req.on("end", () => {
+       resolve(JSON.parse(chunk));
+     });
+   });
​
+ // 写入文件流
+ const pipeStream = (path, writeStream) =>
+  new Promise(resolve => {
+    const readStream = fse.createReadStream(path);
+    readStream.on("end", () => {
+      fse.unlinkSync(path);
+      resolve();
+    });
+    readStream.pipe(writeStream);
+  });
​
// 合并切片
+ const mergeFileChunk = async (filePath, filename, size) => {
+   const chunkDir = path.resolve(UPLOAD_DIR, 'chunkDir' + filename);
+   const chunkPaths = await fse.readdir(chunkDir);
+   // 根据切片下标进行排序
+   // 否则直接读取目录的获得的顺序会错乱
+   chunkPaths.sort((a, b) => a.split("-")[1] - b.split("-")[1]);
+   // 并发写入文件
+   await Promise.all(
+     chunkPaths.map((chunkPath, index) =>
+       pipeStream(
+         path.resolve(chunkDir, chunkPath),
+         // 根据 size 在指定位置创建可写流
+         fse.createWriteStream(filePath, {
+           start: index * size,
+         })
+       )
+     )
+  );
+  // 合并后删除保存切片的目录
+  fse.rmdirSync(chunkDir);
+};
​
server.on("request", async (req, res) => {
  res.setHeader("Access-Control-Allow-Origin", "*");
  res.setHeader("Access-Control-Allow-Headers", "*");
  if (req.method === "OPTIONS") {
    res.status = 200;
    res.end();
    return;
  }
​
+   if (req.url === "/merge") {
+     const data = await resolvePost(req);
+     const { filename,size } = data;
+     const filePath = path.resolve(UPLOAD_DIR, `${filename}`);
+     await mergeFileChunk(filePath, filename);
+     res.end(
+       JSON.stringify({
+         code: 0,
+         message: "file merged success"
+       })
+     );
+   }
​
});
​
server.listen(3000, () => console.log("listening port 3000"));

```

[原文档](https://juejin.cn/post/)
